{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Kumar Sundram'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Case Study\n",
    "# C:\\Users\\Kumar Sundram\\Desktop\\DSP25\\Logistic Regression\n",
    "# Social Networks Ads Data\n",
    "\n",
    "\n",
    "# Import the Library\n",
    "\n",
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\Kumar Sundram\\\\Desktop\\\\my data\\\\DSP25\\\\Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Social_Network_Ads.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15728773</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>58000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15598044</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>84000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15694829</td>\n",
       "      <td>Female</td>\n",
       "      <td>32</td>\n",
       "      <td>150000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15600575</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15727311</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>65000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15570769</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15606274</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>52000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15746139</td>\n",
       "      <td>Male</td>\n",
       "      <td>20</td>\n",
       "      <td>86000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15704987</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>18000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15628972</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>82000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15697686</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15733883</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>25000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15617482</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>26000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>15704583</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>28000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15621083</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>29000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>15649487</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>22000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15736760</td>\n",
       "      <td>Female</td>\n",
       "      <td>47</td>\n",
       "      <td>49000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15714658</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15599081</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>22000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15705113</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15631159</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15792818</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>28000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15633531</td>\n",
       "      <td>Female</td>\n",
       "      <td>47</td>\n",
       "      <td>30000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15744529</td>\n",
       "      <td>Male</td>\n",
       "      <td>29</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15669656</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>18000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>15611430</td>\n",
       "      <td>Female</td>\n",
       "      <td>60</td>\n",
       "      <td>46000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>15774744</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>83000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>15629885</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>73000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>15708791</td>\n",
       "      <td>Male</td>\n",
       "      <td>59</td>\n",
       "      <td>130000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>15793890</td>\n",
       "      <td>Female</td>\n",
       "      <td>37</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>15646091</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>32000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>15596984</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>15800215</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>53000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>15577806</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>87000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>15749381</td>\n",
       "      <td>Female</td>\n",
       "      <td>58</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>15683758</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>64000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>15670615</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>33000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>15715622</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>139000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>15707634</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>28000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>15806901</td>\n",
       "      <td>Female</td>\n",
       "      <td>57</td>\n",
       "      <td>33000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>15775335</td>\n",
       "      <td>Male</td>\n",
       "      <td>56</td>\n",
       "      <td>60000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>15724150</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>39000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>15627220</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>71000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>15672330</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>34000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>15668521</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>35000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>15807837</td>\n",
       "      <td>Male</td>\n",
       "      <td>48</td>\n",
       "      <td>33000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>15592570</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>15748589</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>45000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>15635893</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "      <td>42000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>15757632</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>59000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>15691863</td>\n",
       "      <td>Female</td>\n",
       "      <td>46</td>\n",
       "      <td>41000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>15706071</td>\n",
       "      <td>Male</td>\n",
       "      <td>51</td>\n",
       "      <td>23000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>15654296</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>15755018</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>33000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>15594041</td>\n",
       "      <td>Female</td>\n",
       "      <td>49</td>\n",
       "      <td>36000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0    15624510    Male   19            19000          0\n",
       "1    15810944    Male   35            20000          0\n",
       "2    15668575  Female   26            43000          0\n",
       "3    15603246  Female   27            57000          0\n",
       "4    15804002    Male   19            76000          0\n",
       "5    15728773    Male   27            58000          0\n",
       "6    15598044  Female   27            84000          0\n",
       "7    15694829  Female   32           150000          1\n",
       "8    15600575    Male   25            33000          0\n",
       "9    15727311  Female   35            65000          0\n",
       "10   15570769  Female   26            80000          0\n",
       "11   15606274  Female   26            52000          0\n",
       "12   15746139    Male   20            86000          0\n",
       "13   15704987    Male   32            18000          0\n",
       "14   15628972    Male   18            82000          0\n",
       "15   15697686    Male   29            80000          0\n",
       "16   15733883    Male   47            25000          1\n",
       "17   15617482    Male   45            26000          1\n",
       "18   15704583    Male   46            28000          1\n",
       "19   15621083  Female   48            29000          1\n",
       "20   15649487    Male   45            22000          1\n",
       "21   15736760  Female   47            49000          1\n",
       "22   15714658    Male   48            41000          1\n",
       "23   15599081  Female   45            22000          1\n",
       "24   15705113    Male   46            23000          1\n",
       "25   15631159    Male   47            20000          1\n",
       "26   15792818    Male   49            28000          1\n",
       "27   15633531  Female   47            30000          1\n",
       "28   15744529    Male   29            43000          0\n",
       "29   15669656    Male   31            18000          0\n",
       "..        ...     ...  ...              ...        ...\n",
       "370  15611430  Female   60            46000          1\n",
       "371  15774744    Male   60            83000          1\n",
       "372  15629885  Female   39            73000          0\n",
       "373  15708791    Male   59           130000          1\n",
       "374  15793890  Female   37            80000          0\n",
       "375  15646091  Female   46            32000          1\n",
       "376  15596984  Female   46            74000          0\n",
       "377  15800215  Female   42            53000          0\n",
       "378  15577806    Male   41            87000          1\n",
       "379  15749381  Female   58            23000          1\n",
       "380  15683758    Male   42            64000          0\n",
       "381  15670615    Male   48            33000          1\n",
       "382  15715622  Female   44           139000          1\n",
       "383  15707634    Male   49            28000          1\n",
       "384  15806901  Female   57            33000          1\n",
       "385  15775335    Male   56            60000          1\n",
       "386  15724150  Female   49            39000          1\n",
       "387  15627220    Male   39            71000          0\n",
       "388  15672330    Male   47            34000          1\n",
       "389  15668521  Female   48            35000          1\n",
       "390  15807837    Male   48            33000          1\n",
       "391  15592570    Male   47            23000          1\n",
       "392  15748589  Female   45            45000          1\n",
       "393  15635893    Male   60            42000          1\n",
       "394  15757632  Female   39            59000          0\n",
       "395  15691863  Female   46            41000          1\n",
       "396  15706071    Male   51            23000          1\n",
       "397  15654296  Female   50            20000          1\n",
       "398  15755018    Male   36            33000          0\n",
       "399  15594041  Female   49            36000          1\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,2:4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    19,  19000],\n",
       "       [    35,  20000],\n",
       "       [    26,  43000],\n",
       "       [    27,  57000],\n",
       "       [    19,  76000],\n",
       "       [    27,  58000],\n",
       "       [    27,  84000],\n",
       "       [    32, 150000],\n",
       "       [    25,  33000],\n",
       "       [    35,  65000],\n",
       "       [    26,  80000],\n",
       "       [    26,  52000],\n",
       "       [    20,  86000],\n",
       "       [    32,  18000],\n",
       "       [    18,  82000],\n",
       "       [    29,  80000],\n",
       "       [    47,  25000],\n",
       "       [    45,  26000],\n",
       "       [    46,  28000],\n",
       "       [    48,  29000],\n",
       "       [    45,  22000],\n",
       "       [    47,  49000],\n",
       "       [    48,  41000],\n",
       "       [    45,  22000],\n",
       "       [    46,  23000],\n",
       "       [    47,  20000],\n",
       "       [    49,  28000],\n",
       "       [    47,  30000],\n",
       "       [    29,  43000],\n",
       "       [    31,  18000],\n",
       "       [    31,  74000],\n",
       "       [    27, 137000],\n",
       "       [    21,  16000],\n",
       "       [    28,  44000],\n",
       "       [    27,  90000],\n",
       "       [    35,  27000],\n",
       "       [    33,  28000],\n",
       "       [    30,  49000],\n",
       "       [    26,  72000],\n",
       "       [    27,  31000],\n",
       "       [    27,  17000],\n",
       "       [    33,  51000],\n",
       "       [    35, 108000],\n",
       "       [    30,  15000],\n",
       "       [    28,  84000],\n",
       "       [    23,  20000],\n",
       "       [    25,  79000],\n",
       "       [    27,  54000],\n",
       "       [    30, 135000],\n",
       "       [    31,  89000],\n",
       "       [    24,  32000],\n",
       "       [    18,  44000],\n",
       "       [    29,  83000],\n",
       "       [    35,  23000],\n",
       "       [    27,  58000],\n",
       "       [    24,  55000],\n",
       "       [    23,  48000],\n",
       "       [    28,  79000],\n",
       "       [    22,  18000],\n",
       "       [    32, 117000],\n",
       "       [    27,  20000],\n",
       "       [    25,  87000],\n",
       "       [    23,  66000],\n",
       "       [    32, 120000],\n",
       "       [    59,  83000],\n",
       "       [    24,  58000],\n",
       "       [    24,  19000],\n",
       "       [    23,  82000],\n",
       "       [    22,  63000],\n",
       "       [    31,  68000],\n",
       "       [    25,  80000],\n",
       "       [    24,  27000],\n",
       "       [    20,  23000],\n",
       "       [    33, 113000],\n",
       "       [    32,  18000],\n",
       "       [    34, 112000],\n",
       "       [    18,  52000],\n",
       "       [    22,  27000],\n",
       "       [    28,  87000],\n",
       "       [    26,  17000],\n",
       "       [    30,  80000],\n",
       "       [    39,  42000],\n",
       "       [    20,  49000],\n",
       "       [    35,  88000],\n",
       "       [    30,  62000],\n",
       "       [    31, 118000],\n",
       "       [    24,  55000],\n",
       "       [    28,  85000],\n",
       "       [    26,  81000],\n",
       "       [    35,  50000],\n",
       "       [    22,  81000],\n",
       "       [    30, 116000],\n",
       "       [    26,  15000],\n",
       "       [    29,  28000],\n",
       "       [    29,  83000],\n",
       "       [    35,  44000],\n",
       "       [    35,  25000],\n",
       "       [    28, 123000],\n",
       "       [    35,  73000],\n",
       "       [    28,  37000],\n",
       "       [    27,  88000],\n",
       "       [    28,  59000],\n",
       "       [    32,  86000],\n",
       "       [    33, 149000],\n",
       "       [    19,  21000],\n",
       "       [    21,  72000],\n",
       "       [    26,  35000],\n",
       "       [    27,  89000],\n",
       "       [    26,  86000],\n",
       "       [    38,  80000],\n",
       "       [    39,  71000],\n",
       "       [    37,  71000],\n",
       "       [    38,  61000],\n",
       "       [    37,  55000],\n",
       "       [    42,  80000],\n",
       "       [    40,  57000],\n",
       "       [    35,  75000],\n",
       "       [    36,  52000],\n",
       "       [    40,  59000],\n",
       "       [    41,  59000],\n",
       "       [    36,  75000],\n",
       "       [    37,  72000],\n",
       "       [    40,  75000],\n",
       "       [    35,  53000],\n",
       "       [    41,  51000],\n",
       "       [    39,  61000],\n",
       "       [    42,  65000],\n",
       "       [    26,  32000],\n",
       "       [    30,  17000],\n",
       "       [    26,  84000],\n",
       "       [    31,  58000],\n",
       "       [    33,  31000],\n",
       "       [    30,  87000],\n",
       "       [    21,  68000],\n",
       "       [    28,  55000],\n",
       "       [    23,  63000],\n",
       "       [    20,  82000],\n",
       "       [    30, 107000],\n",
       "       [    28,  59000],\n",
       "       [    19,  25000],\n",
       "       [    19,  85000],\n",
       "       [    18,  68000],\n",
       "       [    35,  59000],\n",
       "       [    30,  89000],\n",
       "       [    34,  25000],\n",
       "       [    24,  89000],\n",
       "       [    27,  96000],\n",
       "       [    41,  30000],\n",
       "       [    29,  61000],\n",
       "       [    20,  74000],\n",
       "       [    26,  15000],\n",
       "       [    41,  45000],\n",
       "       [    31,  76000],\n",
       "       [    36,  50000],\n",
       "       [    40,  47000],\n",
       "       [    31,  15000],\n",
       "       [    46,  59000],\n",
       "       [    29,  75000],\n",
       "       [    26,  30000],\n",
       "       [    32, 135000],\n",
       "       [    32, 100000],\n",
       "       [    25,  90000],\n",
       "       [    37,  33000],\n",
       "       [    35,  38000],\n",
       "       [    33,  69000],\n",
       "       [    18,  86000],\n",
       "       [    22,  55000],\n",
       "       [    35,  71000],\n",
       "       [    29, 148000],\n",
       "       [    29,  47000],\n",
       "       [    21,  88000],\n",
       "       [    34, 115000],\n",
       "       [    26, 118000],\n",
       "       [    34,  43000],\n",
       "       [    34,  72000],\n",
       "       [    23,  28000],\n",
       "       [    35,  47000],\n",
       "       [    25,  22000],\n",
       "       [    24,  23000],\n",
       "       [    31,  34000],\n",
       "       [    26,  16000],\n",
       "       [    31,  71000],\n",
       "       [    32, 117000],\n",
       "       [    33,  43000],\n",
       "       [    33,  60000],\n",
       "       [    31,  66000],\n",
       "       [    20,  82000],\n",
       "       [    33,  41000],\n",
       "       [    35,  72000],\n",
       "       [    28,  32000],\n",
       "       [    24,  84000],\n",
       "       [    19,  26000],\n",
       "       [    29,  43000],\n",
       "       [    19,  70000],\n",
       "       [    28,  89000],\n",
       "       [    34,  43000],\n",
       "       [    30,  79000],\n",
       "       [    20,  36000],\n",
       "       [    26,  80000],\n",
       "       [    35,  22000],\n",
       "       [    35,  39000],\n",
       "       [    49,  74000],\n",
       "       [    39, 134000],\n",
       "       [    41,  71000],\n",
       "       [    58, 101000],\n",
       "       [    47,  47000],\n",
       "       [    55, 130000],\n",
       "       [    52, 114000],\n",
       "       [    40, 142000],\n",
       "       [    46,  22000],\n",
       "       [    48,  96000],\n",
       "       [    52, 150000],\n",
       "       [    59,  42000],\n",
       "       [    35,  58000],\n",
       "       [    47,  43000],\n",
       "       [    60, 108000],\n",
       "       [    49,  65000],\n",
       "       [    40,  78000],\n",
       "       [    46,  96000],\n",
       "       [    59, 143000],\n",
       "       [    41,  80000],\n",
       "       [    35,  91000],\n",
       "       [    37, 144000],\n",
       "       [    60, 102000],\n",
       "       [    35,  60000],\n",
       "       [    37,  53000],\n",
       "       [    36, 126000],\n",
       "       [    56, 133000],\n",
       "       [    40,  72000],\n",
       "       [    42,  80000],\n",
       "       [    35, 147000],\n",
       "       [    39,  42000],\n",
       "       [    40, 107000],\n",
       "       [    49,  86000],\n",
       "       [    38, 112000],\n",
       "       [    46,  79000],\n",
       "       [    40,  57000],\n",
       "       [    37,  80000],\n",
       "       [    46,  82000],\n",
       "       [    53, 143000],\n",
       "       [    42, 149000],\n",
       "       [    38,  59000],\n",
       "       [    50,  88000],\n",
       "       [    56, 104000],\n",
       "       [    41,  72000],\n",
       "       [    51, 146000],\n",
       "       [    35,  50000],\n",
       "       [    57, 122000],\n",
       "       [    41,  52000],\n",
       "       [    35,  97000],\n",
       "       [    44,  39000],\n",
       "       [    37,  52000],\n",
       "       [    48, 134000],\n",
       "       [    37, 146000],\n",
       "       [    50,  44000],\n",
       "       [    52,  90000],\n",
       "       [    41,  72000],\n",
       "       [    40,  57000],\n",
       "       [    58,  95000],\n",
       "       [    45, 131000],\n",
       "       [    35,  77000],\n",
       "       [    36, 144000],\n",
       "       [    55, 125000],\n",
       "       [    35,  72000],\n",
       "       [    48,  90000],\n",
       "       [    42, 108000],\n",
       "       [    40,  75000],\n",
       "       [    37,  74000],\n",
       "       [    47, 144000],\n",
       "       [    40,  61000],\n",
       "       [    43, 133000],\n",
       "       [    59,  76000],\n",
       "       [    60,  42000],\n",
       "       [    39, 106000],\n",
       "       [    57,  26000],\n",
       "       [    57,  74000],\n",
       "       [    38,  71000],\n",
       "       [    49,  88000],\n",
       "       [    52,  38000],\n",
       "       [    50,  36000],\n",
       "       [    59,  88000],\n",
       "       [    35,  61000],\n",
       "       [    37,  70000],\n",
       "       [    52,  21000],\n",
       "       [    48, 141000],\n",
       "       [    37,  93000],\n",
       "       [    37,  62000],\n",
       "       [    48, 138000],\n",
       "       [    41,  79000],\n",
       "       [    37,  78000],\n",
       "       [    39, 134000],\n",
       "       [    49,  89000],\n",
       "       [    55,  39000],\n",
       "       [    37,  77000],\n",
       "       [    35,  57000],\n",
       "       [    36,  63000],\n",
       "       [    42,  73000],\n",
       "       [    43, 112000],\n",
       "       [    45,  79000],\n",
       "       [    46, 117000],\n",
       "       [    58,  38000],\n",
       "       [    48,  74000],\n",
       "       [    37, 137000],\n",
       "       [    37,  79000],\n",
       "       [    40,  60000],\n",
       "       [    42,  54000],\n",
       "       [    51, 134000],\n",
       "       [    47, 113000],\n",
       "       [    36, 125000],\n",
       "       [    38,  50000],\n",
       "       [    42,  70000],\n",
       "       [    39,  96000],\n",
       "       [    38,  50000],\n",
       "       [    49, 141000],\n",
       "       [    39,  79000],\n",
       "       [    39,  75000],\n",
       "       [    54, 104000],\n",
       "       [    35,  55000],\n",
       "       [    45,  32000],\n",
       "       [    36,  60000],\n",
       "       [    52, 138000],\n",
       "       [    53,  82000],\n",
       "       [    41,  52000],\n",
       "       [    48,  30000],\n",
       "       [    48, 131000],\n",
       "       [    41,  60000],\n",
       "       [    41,  72000],\n",
       "       [    42,  75000],\n",
       "       [    36, 118000],\n",
       "       [    47, 107000],\n",
       "       [    38,  51000],\n",
       "       [    48, 119000],\n",
       "       [    42,  65000],\n",
       "       [    40,  65000],\n",
       "       [    57,  60000],\n",
       "       [    36,  54000],\n",
       "       [    58, 144000],\n",
       "       [    35,  79000],\n",
       "       [    38,  55000],\n",
       "       [    39, 122000],\n",
       "       [    53, 104000],\n",
       "       [    35,  75000],\n",
       "       [    38,  65000],\n",
       "       [    47,  51000],\n",
       "       [    47, 105000],\n",
       "       [    41,  63000],\n",
       "       [    53,  72000],\n",
       "       [    54, 108000],\n",
       "       [    39,  77000],\n",
       "       [    38,  61000],\n",
       "       [    38, 113000],\n",
       "       [    37,  75000],\n",
       "       [    42,  90000],\n",
       "       [    37,  57000],\n",
       "       [    36,  99000],\n",
       "       [    60,  34000],\n",
       "       [    54,  70000],\n",
       "       [    41,  72000],\n",
       "       [    40,  71000],\n",
       "       [    42,  54000],\n",
       "       [    43, 129000],\n",
       "       [    53,  34000],\n",
       "       [    47,  50000],\n",
       "       [    42,  79000],\n",
       "       [    42, 104000],\n",
       "       [    59,  29000],\n",
       "       [    58,  47000],\n",
       "       [    46,  88000],\n",
       "       [    38,  71000],\n",
       "       [    54,  26000],\n",
       "       [    60,  46000],\n",
       "       [    60,  83000],\n",
       "       [    39,  73000],\n",
       "       [    59, 130000],\n",
       "       [    37,  80000],\n",
       "       [    46,  32000],\n",
       "       [    46,  74000],\n",
       "       [    42,  53000],\n",
       "       [    41,  87000],\n",
       "       [    58,  23000],\n",
       "       [    42,  64000],\n",
       "       [    48,  33000],\n",
       "       [    44, 139000],\n",
       "       [    49,  28000],\n",
       "       [    57,  33000],\n",
       "       [    56,  60000],\n",
       "       [    49,  39000],\n",
       "       [    39,  71000],\n",
       "       [    47,  34000],\n",
       "       [    48,  35000],\n",
       "       [    48,  33000],\n",
       "       [    47,  23000],\n",
       "       [    45,  45000],\n",
       "       [    60,  42000],\n",
       "       [    39,  59000],\n",
       "       [    46,  41000],\n",
       "       [    51,  23000],\n",
       "       [    50,  20000],\n",
       "       [    36,  33000],\n",
       "       [    49,  36000]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    19,  19000],\n",
       "       [    35,  20000],\n",
       "       [    26,  43000],\n",
       "       [    27,  57000],\n",
       "       [    19,  76000],\n",
       "       [    27,  58000],\n",
       "       [    27,  84000],\n",
       "       [    32, 150000],\n",
       "       [    25,  33000],\n",
       "       [    35,  65000],\n",
       "       [    26,  80000],\n",
       "       [    26,  52000],\n",
       "       [    20,  86000],\n",
       "       [    32,  18000],\n",
       "       [    18,  82000],\n",
       "       [    29,  80000],\n",
       "       [    47,  25000],\n",
       "       [    45,  26000],\n",
       "       [    46,  28000],\n",
       "       [    48,  29000],\n",
       "       [    45,  22000],\n",
       "       [    47,  49000],\n",
       "       [    48,  41000],\n",
       "       [    45,  22000],\n",
       "       [    46,  23000],\n",
       "       [    47,  20000],\n",
       "       [    49,  28000],\n",
       "       [    47,  30000],\n",
       "       [    29,  43000],\n",
       "       [    31,  18000],\n",
       "       [    31,  74000],\n",
       "       [    27, 137000],\n",
       "       [    21,  16000],\n",
       "       [    28,  44000],\n",
       "       [    27,  90000],\n",
       "       [    35,  27000],\n",
       "       [    33,  28000],\n",
       "       [    30,  49000],\n",
       "       [    26,  72000],\n",
       "       [    27,  31000],\n",
       "       [    27,  17000],\n",
       "       [    33,  51000],\n",
       "       [    35, 108000],\n",
       "       [    30,  15000],\n",
       "       [    28,  84000],\n",
       "       [    23,  20000],\n",
       "       [    25,  79000],\n",
       "       [    27,  54000],\n",
       "       [    30, 135000],\n",
       "       [    31,  89000],\n",
       "       [    24,  32000],\n",
       "       [    18,  44000],\n",
       "       [    29,  83000],\n",
       "       [    35,  23000],\n",
       "       [    27,  58000],\n",
       "       [    24,  55000],\n",
       "       [    23,  48000],\n",
       "       [    28,  79000],\n",
       "       [    22,  18000],\n",
       "       [    32, 117000],\n",
       "       [    27,  20000],\n",
       "       [    25,  87000],\n",
       "       [    23,  66000],\n",
       "       [    32, 120000],\n",
       "       [    59,  83000],\n",
       "       [    24,  58000],\n",
       "       [    24,  19000],\n",
       "       [    23,  82000],\n",
       "       [    22,  63000],\n",
       "       [    31,  68000],\n",
       "       [    25,  80000],\n",
       "       [    24,  27000],\n",
       "       [    20,  23000],\n",
       "       [    33, 113000],\n",
       "       [    32,  18000],\n",
       "       [    34, 112000],\n",
       "       [    18,  52000],\n",
       "       [    22,  27000],\n",
       "       [    28,  87000],\n",
       "       [    26,  17000],\n",
       "       [    30,  80000],\n",
       "       [    39,  42000],\n",
       "       [    20,  49000],\n",
       "       [    35,  88000],\n",
       "       [    30,  62000],\n",
       "       [    31, 118000],\n",
       "       [    24,  55000],\n",
       "       [    28,  85000],\n",
       "       [    26,  81000],\n",
       "       [    35,  50000],\n",
       "       [    22,  81000],\n",
       "       [    30, 116000],\n",
       "       [    26,  15000],\n",
       "       [    29,  28000],\n",
       "       [    29,  83000],\n",
       "       [    35,  44000],\n",
       "       [    35,  25000],\n",
       "       [    28, 123000],\n",
       "       [    35,  73000],\n",
       "       [    28,  37000],\n",
       "       [    27,  88000],\n",
       "       [    28,  59000],\n",
       "       [    32,  86000],\n",
       "       [    33, 149000],\n",
       "       [    19,  21000],\n",
       "       [    21,  72000],\n",
       "       [    26,  35000],\n",
       "       [    27,  89000],\n",
       "       [    26,  86000],\n",
       "       [    38,  80000],\n",
       "       [    39,  71000],\n",
       "       [    37,  71000],\n",
       "       [    38,  61000],\n",
       "       [    37,  55000],\n",
       "       [    42,  80000],\n",
       "       [    40,  57000],\n",
       "       [    35,  75000],\n",
       "       [    36,  52000],\n",
       "       [    40,  59000],\n",
       "       [    41,  59000],\n",
       "       [    36,  75000],\n",
       "       [    37,  72000],\n",
       "       [    40,  75000],\n",
       "       [    35,  53000],\n",
       "       [    41,  51000],\n",
       "       [    39,  61000],\n",
       "       [    42,  65000],\n",
       "       [    26,  32000],\n",
       "       [    30,  17000],\n",
       "       [    26,  84000],\n",
       "       [    31,  58000],\n",
       "       [    33,  31000],\n",
       "       [    30,  87000],\n",
       "       [    21,  68000],\n",
       "       [    28,  55000],\n",
       "       [    23,  63000],\n",
       "       [    20,  82000],\n",
       "       [    30, 107000],\n",
       "       [    28,  59000],\n",
       "       [    19,  25000],\n",
       "       [    19,  85000],\n",
       "       [    18,  68000],\n",
       "       [    35,  59000],\n",
       "       [    30,  89000],\n",
       "       [    34,  25000],\n",
       "       [    24,  89000],\n",
       "       [    27,  96000],\n",
       "       [    41,  30000],\n",
       "       [    29,  61000],\n",
       "       [    20,  74000],\n",
       "       [    26,  15000],\n",
       "       [    41,  45000],\n",
       "       [    31,  76000],\n",
       "       [    36,  50000],\n",
       "       [    40,  47000],\n",
       "       [    31,  15000],\n",
       "       [    46,  59000],\n",
       "       [    29,  75000],\n",
       "       [    26,  30000],\n",
       "       [    32, 135000],\n",
       "       [    32, 100000],\n",
       "       [    25,  90000],\n",
       "       [    37,  33000],\n",
       "       [    35,  38000],\n",
       "       [    33,  69000],\n",
       "       [    18,  86000],\n",
       "       [    22,  55000],\n",
       "       [    35,  71000],\n",
       "       [    29, 148000],\n",
       "       [    29,  47000],\n",
       "       [    21,  88000],\n",
       "       [    34, 115000],\n",
       "       [    26, 118000],\n",
       "       [    34,  43000],\n",
       "       [    34,  72000],\n",
       "       [    23,  28000],\n",
       "       [    35,  47000],\n",
       "       [    25,  22000],\n",
       "       [    24,  23000],\n",
       "       [    31,  34000],\n",
       "       [    26,  16000],\n",
       "       [    31,  71000],\n",
       "       [    32, 117000],\n",
       "       [    33,  43000],\n",
       "       [    33,  60000],\n",
       "       [    31,  66000],\n",
       "       [    20,  82000],\n",
       "       [    33,  41000],\n",
       "       [    35,  72000],\n",
       "       [    28,  32000],\n",
       "       [    24,  84000],\n",
       "       [    19,  26000],\n",
       "       [    29,  43000],\n",
       "       [    19,  70000],\n",
       "       [    28,  89000],\n",
       "       [    34,  43000],\n",
       "       [    30,  79000],\n",
       "       [    20,  36000],\n",
       "       [    26,  80000],\n",
       "       [    35,  22000],\n",
       "       [    35,  39000],\n",
       "       [    49,  74000],\n",
       "       [    39, 134000],\n",
       "       [    41,  71000],\n",
       "       [    58, 101000],\n",
       "       [    47,  47000],\n",
       "       [    55, 130000],\n",
       "       [    52, 114000],\n",
       "       [    40, 142000],\n",
       "       [    46,  22000],\n",
       "       [    48,  96000],\n",
       "       [    52, 150000],\n",
       "       [    59,  42000],\n",
       "       [    35,  58000],\n",
       "       [    47,  43000],\n",
       "       [    60, 108000],\n",
       "       [    49,  65000],\n",
       "       [    40,  78000],\n",
       "       [    46,  96000],\n",
       "       [    59, 143000],\n",
       "       [    41,  80000],\n",
       "       [    35,  91000],\n",
       "       [    37, 144000],\n",
       "       [    60, 102000],\n",
       "       [    35,  60000],\n",
       "       [    37,  53000],\n",
       "       [    36, 126000],\n",
       "       [    56, 133000],\n",
       "       [    40,  72000],\n",
       "       [    42,  80000],\n",
       "       [    35, 147000],\n",
       "       [    39,  42000],\n",
       "       [    40, 107000],\n",
       "       [    49,  86000],\n",
       "       [    38, 112000],\n",
       "       [    46,  79000],\n",
       "       [    40,  57000],\n",
       "       [    37,  80000],\n",
       "       [    46,  82000],\n",
       "       [    53, 143000],\n",
       "       [    42, 149000],\n",
       "       [    38,  59000],\n",
       "       [    50,  88000],\n",
       "       [    56, 104000],\n",
       "       [    41,  72000],\n",
       "       [    51, 146000],\n",
       "       [    35,  50000],\n",
       "       [    57, 122000],\n",
       "       [    41,  52000],\n",
       "       [    35,  97000],\n",
       "       [    44,  39000],\n",
       "       [    37,  52000],\n",
       "       [    48, 134000],\n",
       "       [    37, 146000],\n",
       "       [    50,  44000],\n",
       "       [    52,  90000],\n",
       "       [    41,  72000],\n",
       "       [    40,  57000],\n",
       "       [    58,  95000],\n",
       "       [    45, 131000],\n",
       "       [    35,  77000],\n",
       "       [    36, 144000],\n",
       "       [    55, 125000],\n",
       "       [    35,  72000],\n",
       "       [    48,  90000],\n",
       "       [    42, 108000],\n",
       "       [    40,  75000],\n",
       "       [    37,  74000],\n",
       "       [    47, 144000],\n",
       "       [    40,  61000],\n",
       "       [    43, 133000],\n",
       "       [    59,  76000],\n",
       "       [    60,  42000],\n",
       "       [    39, 106000],\n",
       "       [    57,  26000],\n",
       "       [    57,  74000],\n",
       "       [    38,  71000],\n",
       "       [    49,  88000],\n",
       "       [    52,  38000],\n",
       "       [    50,  36000],\n",
       "       [    59,  88000],\n",
       "       [    35,  61000],\n",
       "       [    37,  70000],\n",
       "       [    52,  21000],\n",
       "       [    48, 141000],\n",
       "       [    37,  93000],\n",
       "       [    37,  62000],\n",
       "       [    48, 138000],\n",
       "       [    41,  79000],\n",
       "       [    37,  78000],\n",
       "       [    39, 134000],\n",
       "       [    49,  89000],\n",
       "       [    55,  39000],\n",
       "       [    37,  77000],\n",
       "       [    35,  57000],\n",
       "       [    36,  63000],\n",
       "       [    42,  73000],\n",
       "       [    43, 112000],\n",
       "       [    45,  79000],\n",
       "       [    46, 117000],\n",
       "       [    58,  38000],\n",
       "       [    48,  74000],\n",
       "       [    37, 137000],\n",
       "       [    37,  79000],\n",
       "       [    40,  60000],\n",
       "       [    42,  54000],\n",
       "       [    51, 134000],\n",
       "       [    47, 113000],\n",
       "       [    36, 125000],\n",
       "       [    38,  50000],\n",
       "       [    42,  70000],\n",
       "       [    39,  96000],\n",
       "       [    38,  50000],\n",
       "       [    49, 141000],\n",
       "       [    39,  79000],\n",
       "       [    39,  75000],\n",
       "       [    54, 104000],\n",
       "       [    35,  55000],\n",
       "       [    45,  32000],\n",
       "       [    36,  60000],\n",
       "       [    52, 138000],\n",
       "       [    53,  82000],\n",
       "       [    41,  52000],\n",
       "       [    48,  30000],\n",
       "       [    48, 131000],\n",
       "       [    41,  60000],\n",
       "       [    41,  72000],\n",
       "       [    42,  75000],\n",
       "       [    36, 118000],\n",
       "       [    47, 107000],\n",
       "       [    38,  51000],\n",
       "       [    48, 119000],\n",
       "       [    42,  65000],\n",
       "       [    40,  65000],\n",
       "       [    57,  60000],\n",
       "       [    36,  54000],\n",
       "       [    58, 144000],\n",
       "       [    35,  79000],\n",
       "       [    38,  55000],\n",
       "       [    39, 122000],\n",
       "       [    53, 104000],\n",
       "       [    35,  75000],\n",
       "       [    38,  65000],\n",
       "       [    47,  51000],\n",
       "       [    47, 105000],\n",
       "       [    41,  63000],\n",
       "       [    53,  72000],\n",
       "       [    54, 108000],\n",
       "       [    39,  77000],\n",
       "       [    38,  61000],\n",
       "       [    38, 113000],\n",
       "       [    37,  75000],\n",
       "       [    42,  90000],\n",
       "       [    37,  57000],\n",
       "       [    36,  99000],\n",
       "       [    60,  34000],\n",
       "       [    54,  70000],\n",
       "       [    41,  72000],\n",
       "       [    40,  71000],\n",
       "       [    42,  54000],\n",
       "       [    43, 129000],\n",
       "       [    53,  34000],\n",
       "       [    47,  50000],\n",
       "       [    42,  79000],\n",
       "       [    42, 104000],\n",
       "       [    59,  29000],\n",
       "       [    58,  47000],\n",
       "       [    46,  88000],\n",
       "       [    38,  71000],\n",
       "       [    54,  26000],\n",
       "       [    60,  46000],\n",
       "       [    60,  83000],\n",
       "       [    39,  73000],\n",
       "       [    59, 130000],\n",
       "       [    37,  80000],\n",
       "       [    46,  32000],\n",
       "       [    46,  74000],\n",
       "       [    42,  53000],\n",
       "       [    41,  87000],\n",
       "       [    58,  23000],\n",
       "       [    42,  64000],\n",
       "       [    48,  33000],\n",
       "       [    44, 139000],\n",
       "       [    49,  28000],\n",
       "       [    57,  33000],\n",
       "       [    56,  60000],\n",
       "       [    49,  39000],\n",
       "       [    39,  71000],\n",
       "       [    47,  34000],\n",
       "       [    48,  35000],\n",
       "       [    48,  33000],\n",
       "       [    47,  23000],\n",
       "       [    45,  45000],\n",
       "       [    60,  42000],\n",
       "       [    39,  59000],\n",
       "       [    46,  41000],\n",
       "       [    51,  23000],\n",
       "       [    50,  20000],\n",
       "       [    36,  33000],\n",
       "       [    49,  36000]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "x = sc_x.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.78179743, -1.49004624],\n",
       "       [-0.25358736, -1.46068138],\n",
       "       [-1.11320552, -0.78528968],\n",
       "       [-1.01769239, -0.37418169],\n",
       "       [-1.78179743,  0.18375059],\n",
       "       [-1.01769239, -0.34481683],\n",
       "       [-1.01769239,  0.41866944],\n",
       "       [-0.54012675,  2.35674998],\n",
       "       [-1.20871865, -1.07893824],\n",
       "       [-0.25358736, -0.13926283],\n",
       "       [-1.11320552,  0.30121002],\n",
       "       [-1.11320552, -0.52100597],\n",
       "       [-1.6862843 ,  0.47739916],\n",
       "       [-0.54012675, -1.51941109],\n",
       "       [-1.87731056,  0.35993973],\n",
       "       [-0.82666613,  0.30121002],\n",
       "       [ 0.89257019, -1.3138571 ],\n",
       "       [ 0.70154394, -1.28449224],\n",
       "       [ 0.79705706, -1.22576253],\n",
       "       [ 0.98808332, -1.19639767],\n",
       "       [ 0.70154394, -1.40195167],\n",
       "       [ 0.89257019, -0.60910054],\n",
       "       [ 0.98808332, -0.84401939],\n",
       "       [ 0.70154394, -1.40195167],\n",
       "       [ 0.79705706, -1.37258681],\n",
       "       [ 0.89257019, -1.46068138],\n",
       "       [ 1.08359645, -1.22576253],\n",
       "       [ 0.89257019, -1.16703281],\n",
       "       [-0.82666613, -0.78528968],\n",
       "       [-0.63563988, -1.51941109],\n",
       "       [-0.63563988,  0.12502088],\n",
       "       [-1.01769239,  1.97500684],\n",
       "       [-1.59077117, -1.5781408 ],\n",
       "       [-0.92217926, -0.75592482],\n",
       "       [-1.01769239,  0.59485858],\n",
       "       [-0.25358736, -1.25512738],\n",
       "       [-0.44461362, -1.22576253],\n",
       "       [-0.73115301, -0.60910054],\n",
       "       [-1.11320552,  0.06629116],\n",
       "       [-1.01769239, -1.13766796],\n",
       "       [-1.01769239, -1.54877595],\n",
       "       [-0.44461362, -0.55037082],\n",
       "       [-0.25358736,  1.123426  ],\n",
       "       [-0.73115301, -1.60750566],\n",
       "       [-0.92217926,  0.41866944],\n",
       "       [-1.39974491, -1.46068138],\n",
       "       [-1.20871865,  0.27184516],\n",
       "       [-1.01769239, -0.46227625],\n",
       "       [-0.73115301,  1.91627713],\n",
       "       [-0.63563988,  0.56549373],\n",
       "       [-1.30423178, -1.1083031 ],\n",
       "       [-1.87731056, -0.75592482],\n",
       "       [-0.82666613,  0.38930459],\n",
       "       [-0.25358736, -1.37258681],\n",
       "       [-1.01769239, -0.34481683],\n",
       "       [-1.30423178, -0.4329114 ],\n",
       "       [-1.39974491, -0.63846539],\n",
       "       [-0.92217926,  0.27184516],\n",
       "       [-1.49525804, -1.51941109],\n",
       "       [-0.54012675,  1.38770971],\n",
       "       [-1.01769239, -1.46068138],\n",
       "       [-1.20871865,  0.50676401],\n",
       "       [-1.39974491, -0.10989798],\n",
       "       [-0.54012675,  1.47580428],\n",
       "       [ 2.03872775,  0.38930459],\n",
       "       [-1.30423178, -0.34481683],\n",
       "       [-1.30423178, -1.49004624],\n",
       "       [-1.39974491,  0.35993973],\n",
       "       [-1.49525804, -0.19799255],\n",
       "       [-0.63563988, -0.05116826],\n",
       "       [-1.20871865,  0.30121002],\n",
       "       [-1.30423178, -1.25512738],\n",
       "       [-1.6862843 , -1.37258681],\n",
       "       [-0.44461362,  1.27025028],\n",
       "       [-0.54012675, -1.51941109],\n",
       "       [-0.34910049,  1.24088543],\n",
       "       [-1.87731056, -0.52100597],\n",
       "       [-1.49525804, -1.25512738],\n",
       "       [-0.92217926,  0.50676401],\n",
       "       [-1.11320552, -1.54877595],\n",
       "       [-0.73115301,  0.30121002],\n",
       "       [ 0.12846516, -0.81465453],\n",
       "       [-1.6862843 , -0.60910054],\n",
       "       [-0.25358736,  0.53612887],\n",
       "       [-0.73115301, -0.2273574 ],\n",
       "       [-0.63563988,  1.41707457],\n",
       "       [-1.30423178, -0.4329114 ],\n",
       "       [-0.92217926,  0.4480343 ],\n",
       "       [-1.11320552,  0.33057487],\n",
       "       [-0.25358736, -0.57973568],\n",
       "       [-1.49525804,  0.33057487],\n",
       "       [-0.73115301,  1.35834485],\n",
       "       [-1.11320552, -1.60750566],\n",
       "       [-0.82666613, -1.22576253],\n",
       "       [-0.82666613,  0.38930459],\n",
       "       [-0.25358736, -0.75592482],\n",
       "       [-0.25358736, -1.3138571 ],\n",
       "       [-0.92217926,  1.56389885],\n",
       "       [-0.25358736,  0.09565602],\n",
       "       [-0.92217926, -0.96147882],\n",
       "       [-1.01769239,  0.53612887],\n",
       "       [-0.92217926, -0.31545197],\n",
       "       [-0.54012675,  0.47739916],\n",
       "       [-0.44461362,  2.32738512],\n",
       "       [-1.78179743, -1.43131652],\n",
       "       [-1.59077117,  0.06629116],\n",
       "       [-1.11320552, -1.02020853],\n",
       "       [-1.01769239,  0.56549373],\n",
       "       [-1.11320552,  0.47739916],\n",
       "       [ 0.03295203,  0.30121002],\n",
       "       [ 0.12846516,  0.03692631],\n",
       "       [-0.0625611 ,  0.03692631],\n",
       "       [ 0.03295203, -0.25672226],\n",
       "       [-0.0625611 , -0.4329114 ],\n",
       "       [ 0.41500455,  0.30121002],\n",
       "       [ 0.22397829, -0.37418169],\n",
       "       [-0.25358736,  0.15438573],\n",
       "       [-0.15807423, -0.52100597],\n",
       "       [ 0.22397829, -0.31545197],\n",
       "       [ 0.31949142, -0.31545197],\n",
       "       [-0.15807423,  0.15438573],\n",
       "       [-0.0625611 ,  0.06629116],\n",
       "       [ 0.22397829,  0.15438573],\n",
       "       [-0.25358736, -0.49164111],\n",
       "       [ 0.31949142, -0.55037082],\n",
       "       [ 0.12846516, -0.25672226],\n",
       "       [ 0.41500455, -0.13926283],\n",
       "       [-1.11320552, -1.1083031 ],\n",
       "       [-0.73115301, -1.54877595],\n",
       "       [-1.11320552,  0.41866944],\n",
       "       [-0.63563988, -0.34481683],\n",
       "       [-0.44461362, -1.13766796],\n",
       "       [-0.73115301,  0.50676401],\n",
       "       [-1.59077117, -0.05116826],\n",
       "       [-0.92217926, -0.4329114 ],\n",
       "       [-1.39974491, -0.19799255],\n",
       "       [-1.6862843 ,  0.35993973],\n",
       "       [-0.73115301,  1.09406114],\n",
       "       [-0.92217926, -0.31545197],\n",
       "       [-1.78179743, -1.3138571 ],\n",
       "       [-1.78179743,  0.4480343 ],\n",
       "       [-1.87731056, -0.05116826],\n",
       "       [-0.25358736, -0.31545197],\n",
       "       [-0.73115301,  0.56549373],\n",
       "       [-0.34910049, -1.3138571 ],\n",
       "       [-1.30423178,  0.56549373],\n",
       "       [-1.01769239,  0.77104772],\n",
       "       [ 0.31949142, -1.16703281],\n",
       "       [-0.82666613, -0.25672226],\n",
       "       [-1.6862843 ,  0.12502088],\n",
       "       [-1.11320552, -1.60750566],\n",
       "       [ 0.31949142, -0.72655996],\n",
       "       [-0.63563988,  0.18375059],\n",
       "       [-0.15807423, -0.57973568],\n",
       "       [ 0.22397829, -0.66783025],\n",
       "       [-0.63563988, -1.60750566],\n",
       "       [ 0.79705706, -0.31545197],\n",
       "       [-0.82666613,  0.15438573],\n",
       "       [-1.11320552, -1.16703281],\n",
       "       [-0.54012675,  1.91627713],\n",
       "       [-0.54012675,  0.88850715],\n",
       "       [-1.20871865,  0.59485858],\n",
       "       [-0.0625611 , -1.07893824],\n",
       "       [-0.25358736, -0.93211396],\n",
       "       [-0.44461362, -0.02180341],\n",
       "       [-1.87731056,  0.47739916],\n",
       "       [-1.49525804, -0.4329114 ],\n",
       "       [-0.25358736,  0.03692631],\n",
       "       [-0.82666613,  2.29802026],\n",
       "       [-0.82666613, -0.66783025],\n",
       "       [-1.59077117,  0.53612887],\n",
       "       [-0.34910049,  1.32898   ],\n",
       "       [-1.11320552,  1.41707457],\n",
       "       [-0.34910049, -0.78528968],\n",
       "       [-0.34910049,  0.06629116],\n",
       "       [-1.39974491, -1.22576253],\n",
       "       [-0.25358736, -0.66783025],\n",
       "       [-1.20871865, -1.40195167],\n",
       "       [-1.30423178, -1.37258681],\n",
       "       [-0.63563988, -1.04957339],\n",
       "       [-1.11320552, -1.5781408 ],\n",
       "       [-0.63563988,  0.03692631],\n",
       "       [-0.54012675,  1.38770971],\n",
       "       [-0.44461362, -0.78528968],\n",
       "       [-0.44461362, -0.28608712],\n",
       "       [-0.63563988, -0.10989798],\n",
       "       [-1.6862843 ,  0.35993973],\n",
       "       [-0.44461362, -0.84401939],\n",
       "       [-0.25358736,  0.06629116],\n",
       "       [-0.92217926, -1.1083031 ],\n",
       "       [-1.30423178,  0.41866944],\n",
       "       [-1.78179743, -1.28449224],\n",
       "       [-0.82666613, -0.78528968],\n",
       "       [-1.78179743,  0.00756145],\n",
       "       [-0.92217926,  0.56549373],\n",
       "       [-0.34910049, -0.78528968],\n",
       "       [-0.73115301,  0.27184516],\n",
       "       [-1.6862843 , -0.99084367],\n",
       "       [-1.11320552,  0.30121002],\n",
       "       [-0.25358736, -1.40195167],\n",
       "       [-0.25358736, -0.9027491 ],\n",
       "       [ 1.08359645,  0.12502088],\n",
       "       [ 0.12846516,  1.88691227],\n",
       "       [ 0.31949142,  0.03692631],\n",
       "       [ 1.94321462,  0.917872  ],\n",
       "       [ 0.89257019, -0.66783025],\n",
       "       [ 1.65667523,  1.76945285],\n",
       "       [ 1.37013584,  1.29961514],\n",
       "       [ 0.22397829,  2.12183112],\n",
       "       [ 0.79705706, -1.40195167],\n",
       "       [ 0.98808332,  0.77104772],\n",
       "       [ 1.37013584,  2.35674998],\n",
       "       [ 2.03872775, -0.81465453],\n",
       "       [-0.25358736, -0.34481683],\n",
       "       [ 0.89257019, -0.78528968],\n",
       "       [ 2.13424088,  1.123426  ],\n",
       "       [ 1.08359645, -0.13926283],\n",
       "       [ 0.22397829,  0.2424803 ],\n",
       "       [ 0.79705706,  0.77104772],\n",
       "       [ 2.03872775,  2.15119598],\n",
       "       [ 0.31949142,  0.30121002],\n",
       "       [-0.25358736,  0.62422344],\n",
       "       [-0.0625611 ,  2.18056084],\n",
       "       [ 2.13424088,  0.94723686],\n",
       "       [-0.25358736, -0.28608712],\n",
       "       [-0.0625611 , -0.49164111],\n",
       "       [-0.15807423,  1.65199342],\n",
       "       [ 1.75218836,  1.85754742],\n",
       "       [ 0.22397829,  0.06629116],\n",
       "       [ 0.41500455,  0.30121002],\n",
       "       [-0.25358736,  2.26865541],\n",
       "       [ 0.12846516, -0.81465453],\n",
       "       [ 0.22397829,  1.09406114],\n",
       "       [ 1.08359645,  0.47739916],\n",
       "       [ 0.03295203,  1.24088543],\n",
       "       [ 0.79705706,  0.27184516],\n",
       "       [ 0.22397829, -0.37418169],\n",
       "       [-0.0625611 ,  0.30121002],\n",
       "       [ 0.79705706,  0.35993973],\n",
       "       [ 1.46564897,  2.15119598],\n",
       "       [ 0.41500455,  2.32738512],\n",
       "       [ 0.03295203, -0.31545197],\n",
       "       [ 1.17910958,  0.53612887],\n",
       "       [ 1.75218836,  1.00596657],\n",
       "       [ 0.31949142,  0.06629116],\n",
       "       [ 1.27462271,  2.23929055],\n",
       "       [-0.25358736, -0.57973568],\n",
       "       [ 1.84770149,  1.53453399],\n",
       "       [ 0.31949142, -0.52100597],\n",
       "       [-0.25358736,  0.80041258],\n",
       "       [ 0.60603081, -0.9027491 ],\n",
       "       [-0.0625611 , -0.52100597],\n",
       "       [ 0.98808332,  1.88691227],\n",
       "       [-0.0625611 ,  2.23929055],\n",
       "       [ 1.17910958, -0.75592482],\n",
       "       [ 1.37013584,  0.59485858],\n",
       "       [ 0.31949142,  0.06629116],\n",
       "       [ 0.22397829, -0.37418169],\n",
       "       [ 1.94321462,  0.74168287],\n",
       "       [ 0.70154394,  1.7988177 ],\n",
       "       [-0.25358736,  0.21311545],\n",
       "       [-0.15807423,  2.18056084],\n",
       "       [ 1.65667523,  1.62262856],\n",
       "       [-0.25358736,  0.06629116],\n",
       "       [ 0.98808332,  0.59485858],\n",
       "       [ 0.41500455,  1.123426  ],\n",
       "       [ 0.22397829,  0.15438573],\n",
       "       [-0.0625611 ,  0.12502088],\n",
       "       [ 0.89257019,  2.18056084],\n",
       "       [ 0.22397829, -0.25672226],\n",
       "       [ 0.51051768,  1.85754742],\n",
       "       [ 2.03872775,  0.18375059],\n",
       "       [ 2.13424088, -0.81465453],\n",
       "       [ 0.12846516,  1.06469629],\n",
       "       [ 1.84770149, -1.28449224],\n",
       "       [ 1.84770149,  0.12502088],\n",
       "       [ 0.03295203,  0.03692631],\n",
       "       [ 1.08359645,  0.53612887],\n",
       "       [ 1.37013584, -0.93211396],\n",
       "       [ 1.17910958, -0.99084367],\n",
       "       [ 2.03872775,  0.53612887],\n",
       "       [-0.25358736, -0.25672226],\n",
       "       [-0.0625611 ,  0.00756145],\n",
       "       [ 1.37013584, -1.43131652],\n",
       "       [ 0.98808332,  2.09246627],\n",
       "       [-0.0625611 ,  0.68295315],\n",
       "       [-0.0625611 , -0.2273574 ],\n",
       "       [ 0.98808332,  2.0043717 ],\n",
       "       [ 0.31949142,  0.27184516],\n",
       "       [-0.0625611 ,  0.2424803 ],\n",
       "       [ 0.12846516,  1.88691227],\n",
       "       [ 1.08359645,  0.56549373],\n",
       "       [ 1.65667523, -0.9027491 ],\n",
       "       [-0.0625611 ,  0.21311545],\n",
       "       [-0.25358736, -0.37418169],\n",
       "       [-0.15807423, -0.19799255],\n",
       "       [ 0.41500455,  0.09565602],\n",
       "       [ 0.51051768,  1.24088543],\n",
       "       [ 0.70154394,  0.27184516],\n",
       "       [ 0.79705706,  1.38770971],\n",
       "       [ 1.94321462, -0.93211396],\n",
       "       [ 0.98808332,  0.12502088],\n",
       "       [-0.0625611 ,  1.97500684],\n",
       "       [-0.0625611 ,  0.27184516],\n",
       "       [ 0.22397829, -0.28608712],\n",
       "       [ 0.41500455, -0.46227625],\n",
       "       [ 1.27462271,  1.88691227],\n",
       "       [ 0.89257019,  1.27025028],\n",
       "       [-0.15807423,  1.62262856],\n",
       "       [ 0.03295203, -0.57973568],\n",
       "       [ 0.41500455,  0.00756145],\n",
       "       [ 0.12846516,  0.77104772],\n",
       "       [ 0.03295203, -0.57973568],\n",
       "       [ 1.08359645,  2.09246627],\n",
       "       [ 0.12846516,  0.27184516],\n",
       "       [ 0.12846516,  0.15438573],\n",
       "       [ 1.5611621 ,  1.00596657],\n",
       "       [-0.25358736, -0.4329114 ],\n",
       "       [ 0.70154394, -1.1083031 ],\n",
       "       [-0.15807423, -0.28608712],\n",
       "       [ 1.37013584,  2.0043717 ],\n",
       "       [ 1.46564897,  0.35993973],\n",
       "       [ 0.31949142, -0.52100597],\n",
       "       [ 0.98808332, -1.16703281],\n",
       "       [ 0.98808332,  1.7988177 ],\n",
       "       [ 0.31949142, -0.28608712],\n",
       "       [ 0.31949142,  0.06629116],\n",
       "       [ 0.41500455,  0.15438573],\n",
       "       [-0.15807423,  1.41707457],\n",
       "       [ 0.89257019,  1.09406114],\n",
       "       [ 0.03295203, -0.55037082],\n",
       "       [ 0.98808332,  1.44643942],\n",
       "       [ 0.41500455, -0.13926283],\n",
       "       [ 0.22397829, -0.13926283],\n",
       "       [ 1.84770149, -0.28608712],\n",
       "       [-0.15807423, -0.46227625],\n",
       "       [ 1.94321462,  2.18056084],\n",
       "       [-0.25358736,  0.27184516],\n",
       "       [ 0.03295203, -0.4329114 ],\n",
       "       [ 0.12846516,  1.53453399],\n",
       "       [ 1.46564897,  1.00596657],\n",
       "       [-0.25358736,  0.15438573],\n",
       "       [ 0.03295203, -0.13926283],\n",
       "       [ 0.89257019, -0.55037082],\n",
       "       [ 0.89257019,  1.03533143],\n",
       "       [ 0.31949142, -0.19799255],\n",
       "       [ 1.46564897,  0.06629116],\n",
       "       [ 1.5611621 ,  1.123426  ],\n",
       "       [ 0.12846516,  0.21311545],\n",
       "       [ 0.03295203, -0.25672226],\n",
       "       [ 0.03295203,  1.27025028],\n",
       "       [-0.0625611 ,  0.15438573],\n",
       "       [ 0.41500455,  0.59485858],\n",
       "       [-0.0625611 , -0.37418169],\n",
       "       [-0.15807423,  0.85914229],\n",
       "       [ 2.13424088, -1.04957339],\n",
       "       [ 1.5611621 ,  0.00756145],\n",
       "       [ 0.31949142,  0.06629116],\n",
       "       [ 0.22397829,  0.03692631],\n",
       "       [ 0.41500455, -0.46227625],\n",
       "       [ 0.51051768,  1.74008799],\n",
       "       [ 1.46564897, -1.04957339],\n",
       "       [ 0.89257019, -0.57973568],\n",
       "       [ 0.41500455,  0.27184516],\n",
       "       [ 0.41500455,  1.00596657],\n",
       "       [ 2.03872775, -1.19639767],\n",
       "       [ 1.94321462, -0.66783025],\n",
       "       [ 0.79705706,  0.53612887],\n",
       "       [ 0.03295203,  0.03692631],\n",
       "       [ 1.5611621 , -1.28449224],\n",
       "       [ 2.13424088, -0.69719511],\n",
       "       [ 2.13424088,  0.38930459],\n",
       "       [ 0.12846516,  0.09565602],\n",
       "       [ 2.03872775,  1.76945285],\n",
       "       [-0.0625611 ,  0.30121002],\n",
       "       [ 0.79705706, -1.1083031 ],\n",
       "       [ 0.79705706,  0.12502088],\n",
       "       [ 0.41500455, -0.49164111],\n",
       "       [ 0.31949142,  0.50676401],\n",
       "       [ 1.94321462, -1.37258681],\n",
       "       [ 0.41500455, -0.16862769],\n",
       "       [ 0.98808332, -1.07893824],\n",
       "       [ 0.60603081,  2.03373655],\n",
       "       [ 1.08359645, -1.22576253],\n",
       "       [ 1.84770149, -1.07893824],\n",
       "       [ 1.75218836, -0.28608712],\n",
       "       [ 1.08359645, -0.9027491 ],\n",
       "       [ 0.12846516,  0.03692631],\n",
       "       [ 0.89257019, -1.04957339],\n",
       "       [ 0.98808332, -1.02020853],\n",
       "       [ 0.98808332, -1.07893824],\n",
       "       [ 0.89257019, -1.37258681],\n",
       "       [ 0.70154394, -0.72655996],\n",
       "       [ 2.13424088, -0.81465453],\n",
       "       [ 0.12846516, -0.31545197],\n",
       "       [ 0.79705706, -0.84401939],\n",
       "       [ 1.27462271, -1.37258681],\n",
       "       [ 1.17910958, -1.46068138],\n",
       "       [-0.15807423, -1.07893824],\n",
       "       [ 1.08359645, -0.99084367]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data into training and test\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=100)\n",
    "\n",
    "# size - by default (training = 75% and test = 25%) and random_state \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "\n",
    "logmodel.fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Logistic Regression value\n",
    "\n",
    "\n",
    "\n",
    "y_pred = logmodel.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  3],\n",
       "       [12, 23]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "accuracy = (62+23)/(62+3+12+23)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Reg = 85%\n",
    "# Decision Tree = 87%\n",
    "# Random Forest = 89%\n",
    "# Bagging Concept = 87%\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier_dt = DecisionTreeClassifier(criterion = 'entropy')\n",
    "classifier_dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = classifier_dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60,  5],\n",
       "       [ 8, 27]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "87/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=50, n_jobs=None, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bgcl = BaggingClassifier(n_estimators = 50,max_samples=1.0)\n",
    "bgcl.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bg = bgcl.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60,  5],\n",
       "       [ 8, 27]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "87/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Reg = 85%\n",
    "# Decision Tree = 87%\n",
    "# Random Forest = 89%\n",
    "# Bagging Concept = 87%\n",
    "\n",
    "# Final - Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=5000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Classifier1 = RandomForestClassifier(n_estimators=5000, criterion='entropy')\n",
    "Classifier1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = Classifier1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  3],\n",
       "       [ 8, 27]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "89/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix - other component\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89        65\n",
      "           1       0.88      0.66      0.75        35\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       100\n",
      "   macro avg       0.86      0.81      0.82       100\n",
      "weighted avg       0.85      0.85      0.84       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curve = Receiver Operating Characteristic \n",
    "# AUC = Area Under Curve\n",
    "# Maximum Likelihood Ratio = Algorithm = Cut-off value and best accuracy percentage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8054945054945054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Let us measure the Logistic Regression model by the help of ROC and AUC curve\n",
    "\n",
    "logistic_roc_auc = roc_auc_score(y_test,y_pred)\n",
    "print(logistic_roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.04615385, 1.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.65714286, 1.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display (thresholds[:10])\n",
    "display (fpr[:10])\n",
    "display (tpr[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28851026, 0.33331688, 0.06748258, 0.38593838, 0.0904378 ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmodel.predict_proba(x_test)[:,1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Auc = 0.81\n"
     ]
    }
   ],
   "source": [
    "#Visualisation for ROC and AUC Curve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Plot of ROC Curve for specific class\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label = 'ROC Curve (area= %0.2f)' %logistic_roc_auc)\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Exampls')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('Logistic Auc = %2.2f'%logistic_roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold method\n",
    "#XGBOOST\n",
    "#ADABOOST\n",
    "#Ensemble Techniques - Forget all otehr classification and only remember \"Ensemble Techniques\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Reg = 85%\n",
    "# Decision Tree = 87%\n",
    "# Random Forest = 89% - if you are not able to predict properly with other algorithm\n",
    "# Bagging Concept = 87%\n",
    "\n",
    "# SVM - Bots (Artificial Intelligence)\n",
    "# KNN - Clinical sector data /Small dataset\n",
    "# Naive Bayes Theorem  - adhoc project / urgent request\n",
    "\n",
    "# Ensemble tech - Very very important  - no need to use any other algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine - Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='sigmoid', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier_svm_sigmoid = SVC(kernel = 'sigmoid') # Kernel  - approach\n",
    "classifier_svm_sigmoid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_svm_sigmoid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52, 13],\n",
       "       [ 9, 26]], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(52+26)/(52+13+9+26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Reg = 85%\n",
    "# Decision Tree = 87%\n",
    "# Random Forest = 89% - if you are not able to predict properly with other algorithm\n",
    "# Bagging Concept = 87%\n",
    "\n",
    "# SVM - Bots (Artificial Intelligence) - 78% \n",
    "# KNN - Clinical sector data /Small dataset\n",
    "# Naive Bayes Theorem  - adhoc project / urgent request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine - RBF (Radial Basis Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier_svm_rbf = SVC(kernel = 'rbf') # Kernel  - approach\n",
    "classifier_svm_rbf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier_svm_rbf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  3],\n",
       "       [ 5, 30]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(62+30)/(62+3+5+30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Reg = 85%\n",
    "# Decision Tree = 87%\n",
    "# Random Forest = 89% - if you are not able to predict properly with other algorithm\n",
    "# Bagging Concept = 87%\n",
    "\n",
    "# SVM (Sigmoid) - Bots (Artificial Intelligence) - 78% \n",
    "# SVM (rbf) - Bots (Artificial Intelligence) - 92% \n",
    "# KNN - Clinical sector data /Small dataset\n",
    "# Naive Bayes Theorem  - adhoc project / urgent request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p=2)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# minkowski is the scientist name who has given eucliean methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[63,  2],\n",
       "       [ 6, 29]], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(63+29)/(63+2+6+29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = (2+6)/(63+2+6+29)\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Reg = 85%\n",
    "# Decision Tree = 87%\n",
    "# Random Forest = 89% - if you are not able to predict properly with other algorithm\n",
    "# Bagging Concept = 87%\n",
    "\n",
    "# SVM (Sigmoid) - Bots (Artificial Intelligence) - 78% \n",
    "# SVM (rbf) - Bots (Artificial Intelligence) - 92% \n",
    "# KNN - Clinical sector data /Small dataset - 92%\n",
    "# Naive Bayes Theorem  - adhoc project / urgent request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Theorem - adhoc algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB \n",
    "classifier = GaussianNB()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  3],\n",
       "       [10, 25]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(62+25)/(62+3+10+25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Reg = 85%\n",
    "# Decision Tree = 87%\n",
    "# Random Forest = 89% - if you are not able to predict properly with other algorithm\n",
    "# Bagging Concept = 87%\n",
    "\n",
    "# SVM (Sigmoid) - Bots (Artificial Intelligence) - 78% \n",
    "# SVM (rbf) - Bots (Artificial Intelligence) - 92% \n",
    "# KNN - Clinical sector data /Small dataset - 92%\n",
    "# Naive Bayes Theorem  - adhoc project / urgent request - 87% \n",
    "\n",
    "# Kernal PCA (Principal Component Analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernal PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "kpca = KernelPCA(n_components = 2 , kernel = 'rbf')\n",
    "x_train = kpca.fit_transform(x_train)\n",
    "x_test = kpca.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=1000, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression(random_state = 1000)\n",
    "\n",
    "logmodel.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logmodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  3],\n",
       "       [ 9, 26]], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(62+26)/(62+3+9+26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Reg = 85%\n",
    "# Decision Tree = 87%\n",
    "# Random Forest = 89% - if you are not able to predict properly with other algorithm\n",
    "# Bagging Concept = 87%\n",
    "\n",
    "# SVM (Sigmoid) - Bots (Artificial Intelligence) - 78% \n",
    "# SVM (rbf) - Bots (Artificial Intelligence) - 92% \n",
    "# KNN - Clinical sector data /Small dataset - 92%\n",
    "# Naive Bayes Theorem  - adhoc project / urgent request - 87% \n",
    "\n",
    "# Kernal PCA (Principal Component Analysis) - 88% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classfier = XGBClassifier()\n",
    "classfier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classfier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62,  3],\n",
       "       [ 7, 28]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(62+28)/(62+3+7+28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Reg = 85%\n",
    "# Decision Tree = 87%\n",
    "# Random Forest = 89% - if you are not able to predict properly with other algorithm\n",
    "# Bagging Concept = 87%\n",
    "\n",
    "# SVM (Sigmoid) - Bots (Artificial Intelligence) - 78% \n",
    "# SVM (rbf) - Bots (Artificial Intelligence) - 92% \n",
    "# KNN - Clinical sector data /Small dataset - 92% (Lazy algorithm)\n",
    "# Naive Bayes Theorem  - adhoc project / urgent request - 87% \n",
    "\n",
    "# Kernal PCA (Principal Component Analysis) - 88% \n",
    "\n",
    "# XGBoost Methods - 90% (when you have huge data and there are regular descripency in accuracy with other algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Result **\n",
    "---\n",
    "# SVM (rbf) - 92%\n",
    "---\n",
    "## XGBoost  - 90% (this is my recommandation to go ahead with this algorithm)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
